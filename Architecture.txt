Virtual 3D Models

This paper introduces my third-year project, an independent endeavour that is nearing completion but still a work in progress. The entirety of the codebase has been crafted in C++, chosen for its superior speed compared to numerous other programming languages, making it ideal for applications demanding significant execution time. The primary objective of this project is to reconstruct virtual 3D models using either videos or a collection of images depicting a room, an object, or an outdoor space. To realize this goal, I have implemented a highly efficient and complex algorithm known as SFM (structure from motion). The steps for achieving the result are the following:

1. Image Acquisition:
I carefully selected the camera setup based on the nature of the project, ensuring it was mounted on a platform that allowed for controlled movement.
As I navigated through the environment, I captured a continuous sequence of images, adjusting for factors like lighting conditions and camera settings.

2. Camera Calibration:
I meticulously prepared for camera calibration by capturing images of a chessboard or a known calibration pattern from various angles and distances.
Using these images, I applied calibration algorithms to determine intrinsic parameters, correcting for lens distortion and ensuring precise measurements.

3. Feature Extraction:
Implementing feature extraction, I employed algorithms like SURF, SIFT or ORB to identify and describe key features in each image. After conducting numerous tests, I have concluded that, despite the ORB detector's focus on the most relevant features of an image, SURF or SIFT prove to be superior choices for this project. Their ability to identify a larger number of features significantly enhances the reconstruction process, particularly when dealing with highly detailed objects.
I fine-tuned parameters to balance feature quantity and quality, crucial for subsequent matching accuracy.

4. Feature Matching:
Feature matching is a critical step where I establish correspondences between key features detected in different images.
Two approaches I employed are the brute force matching technique and the FLANN matcher.
Brute Force Matching:
In brute force matching, I exhaustively compare each feature in one image with every feature in another image.
This straightforward approach ensures a thorough examination of all possible matches.
However, it can be computationally expensive, especially with large feature sets.
FLANN Matcher:
FLANN matcher is an alternative that provides a more efficient approach, especially with large datasets.
The FLANN matcher allows for approximate nearest neighbour searches, making it faster and suitable for real-time applications.
It's particularly useful when dealing with high-dimensional feature spaces.
While brute force matching guarantees accuracy, FLANN offers a speed advantage, especially in scenarios where real-time performance is crucial.
After conducting extensive tests on various datasets, I have determined that employing the FLANN matcher in conjunction with features detected by the ORB detector results in minimal matches. Therefore, the optimal approach is to either pair the ORB detector with brute force matching or combine SURF or SIFT with the FLANN matcher for better matching outcomes.

5. Point Cloud Generation:
Triangulation became a key component, involving careful consideration of numerical stability and precision in the reconstruction process.
In triangulation, I aim to determine the 3D coordinates of a point in space by intersecting the lines of sight from multiple cameras.
Mathematical Basis:
I leverage the fundamental principle of triangulation, which involves the intersection of projection rays from two or more cameras onto the 2D image plane.
By using the camera matrices P1 and P2 along with the corresponding image points x1 and x2, I compute the 3D point X through linear algebra.
Challenges:
I grapple with cases where the rays from different cameras fail to intersect, leading to degenerate situations.
I diligently handle outliers and noise in correspondence data, as they pose a constant threat to the precision of triangulated points.

6. Bundle Adjustment:
In the upcoming steps, I will delve into Bundle Adjustment, a pivotal process for refining both camera poses and 3D points simultaneously.
With the initial set of 3D points and camera poses, I will set up the Bundle Adjustment framework.
I will organize the parameters, including camera poses, translation vectors, and 3D points, into a single vector for optimization.
Anticipating the need for optimization, I will define the objective function for Bundle Adjustment.
This function will encapsulate the reprojection error, the discrepancy between the projected 3D points and the actual 2D image points.
In the imminent steps, I will execute Bundle Adjustment using the defined objective function and the initial parameter estimates.
This process will iteratively refine the camera poses and 3D points, optimizing them to minimize the reprojection error.
